{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, process_pdf\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from io import StringIO\n",
    "from io import open\n",
    "from urllib.request import urlopen\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf_file(pdfFile):\n",
    "    pdfrm = PDFResourceManager()\n",
    "    strio = StringIO()\n",
    "    lapa = LAParams()\n",
    "    device = TextConverter(pdfrm, strio, laparams = lapa)\n",
    "    \n",
    "    process_pdf(pdfrm, device, pdfFile)\n",
    "    device.close()\n",
    "    \n",
    "    content = strio.getvalue()\n",
    "    strio.close()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=521\n",
      "WARNING:pdfminer.layout:Too many boxes (167) to group, skipping.\n",
      "WARNING:root:Cannot locate objid=536\n",
      "WARNING:root:Cannot locate objid=612\n",
      "WARNING:root:Cannot locate objid=588\n",
      "WARNING:root:Cannot locate objid=505\n",
      "WARNING:pdfminer.layout:Too many boxes (104) to group, skipping.\n"
     ]
    }
   ],
   "source": [
    "pdf_a = open(\"data/ESG_Mid/더블유원.pdf\", \"rb\")\n",
    "a = read_pdf_file(pdf_a)\n",
    "pdf_a.close() \n",
    "\n",
    "pdf_b = open(\"data/ESG_Mid/동림푸드.pdf\", \"rb\")\n",
    "b = read_pdf_file(pdf_b)\n",
    "pdf_b.close()\n",
    "\n",
    "pdf_c = open(\"data/ESG_Mid/선일금고.pdf\", \"rb\")\n",
    "c = read_pdf_file(pdf_c)\n",
    "pdf_c.close()\n",
    "\n",
    "pdf_d = open(\"data/ESG_Mid/세림비앤지.pdf\", \"rb\")\n",
    "d = read_pdf_file(pdf_d)\n",
    "pdf_d.close()\n",
    "\n",
    "pdf_e = open(\"data/ESG_Mid/지리산한지.pdf\", \"rb\")\n",
    "e = read_pdf_file(pdf_e)\n",
    "pdf_e.close()\n",
    "\n",
    "pdf_f = open(\"data/ESG_Mid/창명제어기술.pdf\", \"rb\")\n",
    "f = read_pdf_file(pdf_f)\n",
    "pdf_f.close() \n",
    "\n",
    "pdf_g = open(\"data/ESG_Mid/티제이에스.pdf\", \"rb\")\n",
    "g = read_pdf_file(pdf_g)\n",
    "pdf_g.close()\n",
    "\n",
    "pdf_h = open(\"data/ESG_Mid/한아툴스.pdf\", \"rb\")\n",
    "h = read_pdf_file(pdf_h)\n",
    "pdf_h.close()\n",
    "\n",
    "pdf_i = open(\"data/ESG_Mid/현대아이티.pdf\", \"rb\")\n",
    "i = read_pdf_file(pdf_i)\n",
    "pdf_i.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "\n",
    "def word_token (x) :\n",
    "    tokens = []\n",
    "    for token in mecab.pos(x):\n",
    "        tokens.append(token)\n",
    "    return tokens\n",
    "\n",
    "a = word_token(a)\n",
    "b = word_token(b)\n",
    "c = word_token(c)\n",
    "d = word_token(d)\n",
    "e = word_token(e)\n",
    "f = word_token(f)\n",
    "g = word_token(g)\n",
    "h = word_token(h)\n",
    "i = word_token(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "stop = [\"회사\", \"에서\", \"위해\", \"관련\", \"기준\"]\n",
    "\n",
    "def vocab_nodes (x):\n",
    "    nodes = [t[0] for t in x]\n",
    "    vocab = [t[0] for t in x if t[0] not in stop if t[1] in ['NNG', 'NNP'] and len(t[0]) > 1]\n",
    "    \n",
    "    vocab = list(set(vocab))\n",
    "\n",
    "    vocab2idx = {vocab[i]:i for i in range(len(vocab))}\n",
    "    idx2vocab = {i:vocab[i] for i in range(len(vocab))}\n",
    "    \n",
    "    vocab_len = len(vocab2idx)\n",
    "\n",
    "    # 토큰별로 그래프 edge를 Matrix 형태로 생성\n",
    "    weighted_edge = np.zeros((vocab_len,vocab_len),dtype=np.float32)\n",
    "\n",
    "    # 각 토큰 노드별로 스코어 1로 초기화\n",
    "    score = np.ones((vocab_len),dtype=np.float32)\n",
    "\n",
    "    # coocurrence를 판단하기 위한 window 사이즈 설정\n",
    "    window_size = 4\n",
    "    covered_coocurrences = []\n",
    "\n",
    "    for window_start in range(len(nodes) - window_size + 1):\n",
    "        window = nodes[window_start:window_start+window_size]\n",
    "        for i in range(window_size):\n",
    "            for j in range(i+1, window_size):\n",
    "                if window[i] in vocab and window[j] in vocab:\n",
    "                    index_i = window_start + i\n",
    "                    index_j = window_start + j\n",
    "\n",
    "                    if (index_i, index_j) not in covered_coocurrences:\n",
    "                        weighted_edge[vocab2idx[window[i]]][vocab2idx[window[j]]] = 1\n",
    "                        weighted_edge[vocab2idx[window[j]]][vocab2idx[window[i]]] = 1\n",
    "                        covered_coocurrences.append((index_i, index_j))\n",
    "\n",
    "    for i in range(vocab_len):\n",
    "        row_sum = weighted_edge[i].sum()\n",
    "        weighted_edge[i] = weighted_edge[i]/row_sum if row_sum > 0 else 0\n",
    "\n",
    "    MAX_ITERATIONS = 50\n",
    "    d=0.85\n",
    "    threshold = 0.0001 #convergence threshold\n",
    "\n",
    "    for iter in range(MAX_ITERATIONS):\n",
    "        prev_score = np.copy(score)\n",
    "\n",
    "        for i in range(vocab_len):\n",
    "            summation = 0\n",
    "            for j in range(vocab_len):\n",
    "                if weighted_edge[j][i] != 0:\n",
    "                    summation += weighted_edge[j][i] * prev_score[j]\n",
    "\n",
    "            score[i] = (1 - d) * d*summation\n",
    "\n",
    "        if np.sum(np.fabs(prev_score -  score)) <= threshold:\n",
    "            break\n",
    "\n",
    "\n",
    "    sorted_index = np.flip(np.argsort(score), 0)\n",
    "\n",
    "    w = []\n",
    "    v = []\n",
    "    for i in range(0, 100) :\n",
    "        w.append(str(idx2vocab[sorted_index[i]]))\n",
    "        v.append(str(score[sorted_index[i]]))\n",
    "    return w, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0, v0 = vocab_nodes (a)\n",
    "w1, v1 = vocab_nodes (b)\n",
    "w2, v2 = vocab_nodes (c)\n",
    "w3, v3 = vocab_nodes (d)\n",
    "w4, v4 = vocab_nodes (e)\n",
    "w5, v5 = vocab_nodes (f)\n",
    "w6, v6 = vocab_nodes (g)\n",
    "w7, v7 = vocab_nodes (h)\n",
    "w8, v8 = vocab_nodes (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = []\n",
    "for i in range(1, 101):\n",
    "    attr.append(f\"속성{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = pd.Series(w0, attr)\n",
    "w1 = pd.Series(w1, attr)\n",
    "w2 = pd.Series(w2, attr)\n",
    "w3 = pd.Series(w3, attr)\n",
    "w4 = pd.Series(w4, attr)\n",
    "w5 = pd.Series(w5, attr)\n",
    "w6 = pd.Series(w6, attr)\n",
    "w7 = pd.Series(w7, attr)\n",
    "w8 = pd.Series(w8, attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([w0, w1, w2, w3, w4, w5, w6, w7, w8], index=[1, 2, 3, 4, 5, 6, 7, 8, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(index=range(0, 9), columns=[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label (x) :\n",
    "    col_list = list(df[x])\n",
    "    en = LabelEncoder()\n",
    "    en.fit(df[x])\n",
    "    x_list = en.transform(df[x])\n",
    "    \n",
    "    return x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in df:\n",
    "    a.append(label(f\"{i}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = pd.DataFrame(data = a, columns=[x for x in range(1, 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = df_label.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standard = pd.read_csv(\"data/csv/label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_standard.drop([\"y\", \"Unnamed: 0\"], axis=1, inplace = False)\n",
    "df_target = df_standard[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = RandomForestRegressor()\n",
    "\n",
    "model1.fit(df_train, df_target)\n",
    "\n",
    "\n",
    "pred1 = model1.predict(df_label)\n",
    "\n",
    "df_result['result'] = pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>93.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>93.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>93.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>93.220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   result\n",
       "0  93.478\n",
       "1  93.469\n",
       "2  93.100\n",
       "3  93.075\n",
       "4  93.500\n",
       "5  93.190\n",
       "6  93.025\n",
       "7  93.499\n",
       "8  93.220"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
